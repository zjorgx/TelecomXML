# ğŸ“Š PredicciÃ³n de Churn â€“ Telecom X  

## ğŸ“‘ DescripciÃ³n del Proyecto  
Este proyecto tiene como objetivo **predecir la cancelaciÃ³n de clientes (churn) en la empresa Telecom X**, utilizando tÃ©cnicas de **Machine Learning** aplicadas a un dataset de clientes.  

El churn es uno de los principales desafÃ­os en la industria de telecomunicaciones, ya que afecta directamente la rentabilidad. Con modelos predictivos robustos, se busca identificar clientes en riesgo de abandono y diseÃ±ar estrategias de retenciÃ³n efectivas.  

---

## ğŸ¯ Objetivos  
- Analizar los factores que influyen en el churn de clientes.  
- Construir y comparar modelos de clasificaciÃ³n para predecir churn.  
- Identificar segmentos de clientes con mayor riesgo.  
- Generar recomendaciones de negocio para reducir la fuga de clientes.  

---
## ğŸ“Š Dataset  

- **Registros:** 7,267 clientes  
- **Variables:** 21 (demogrÃ¡ficas, servicios, mÃ©todos de pago, historial de facturaciÃ³n y churn)  
- **Variable objetivo:** `Churn` (1 = cliente se da de baja, 0 = cliente permanece)  

**Hallazgos clave:**  
- 71% clientes permanecen, 25.7% churn, 3% registros eliminados por vacÃ­os.  
- **Factores crÃ­ticos:** contrato mensual, tenure < 12 meses, uso de "Electronic check", falta de servicios de seguridad/soporte, internet "Fiber optic".  
- **Factores poco relevantes:** gÃ©nero y mÃºltiples lÃ­neas.  

---

## ğŸ¤– Modelos Entrenados  

| Modelo                  | AUC  | Recall | Precision | F1   | Observaciones |
|-------------------------|------|--------|-----------|------|---------------|
| Random Forest           | 0.84 | 0.76   | 0.56      | 0.64 | Buen balance entre desempeÃ±o e interpretabilidad |
| XGBoost                 | 0.85 | 0.82   | 0.54      | 0.64 | Mejor desempeÃ±o global |
| Red Neuronal (MLP)      | 0.84 | 0.83   | 0.49      | 0.60 | Ãštil, pero menos interpretable |

ğŸ‘‰ El **XGBoost** fue el modelo con mejor desempeÃ±o global, aunque Random Forest resulta mÃ¡s interpretable para el negocio.  

---

## ğŸ§© MetodologÃ­a  

1. **PreparaciÃ³n de datos**  
   - Limpieza de nulos, codificaciÃ³n de variables categÃ³ricas y escalado.  
   - Balanceo de clases con tÃ©cnicas de sobremuestreo.  

2. **SelecciÃ³n de variables**  
   - AnÃ¡lisis de correlaciÃ³n.  
   - Importancia de variables con Random Forest y XGBoost.  

3. **Modelado**  
   - RegresiÃ³n LogÃ­stica  
   - KNN  
   - SVM (lineal y RBF)  
   - Random Forest  
   - XGBoost  
   - Red Neuronal (MLP)  

4. **EvaluaciÃ³n**  
   - MÃ©tricas: Accuracy, Recall, Precision, F1, AUC-ROC.  
   - ValidaciÃ³n cruzada y ajuste de hiperparÃ¡metros (GridSearch).  

---

## ğŸ’¡ Recomendaciones de Negocio  

- Migrar clientes de **contratos mensuales** a planes anuales con incentivos.  
- Promover **servicios adicionales** (seguridad, soporte, protecciÃ³n de dispositivos).  
- Incentivar el cambio de **Electronic check** a pagos automÃ¡ticos.  
- Implementar un **programa de fidelizaciÃ³n por antigÃ¼edad** (6 y 12 meses).  
- Activar **alertas proactivas** en clientes de alto riesgo (tenure bajo, contrato M2M, mÃ©todo de pago riesgoso).  

---

## ğŸ“Œ ConclusiÃ³n  

El churn en Telecom X es **altamente predecible** con AUC de hasta **0.85 (XGBoost)**.  
Las variables mÃ¡s influyentes (tipo de contrato, servicios extra y mÃ©todo de pago) representan palancas de acciÃ³n directa para el negocio.  

La implementaciÃ³n de estas estrategias puede reducir el churn anual en **8-12 puntos porcentuales**, con un impacto financiero significativo.  

---

## ğŸš€ PrÃ³ximos Pasos  

- Desplegar el modelo XGBoost en producciÃ³n.  
- Integrar alertas automÃ¡ticas en el CRM.  
- Ejecutar campaÃ±as de retenciÃ³n segmentadas en el prÃ³ximo trimestre.  

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas  

- Python (pandas, numpy, scikit-learn, imbalanced-learn)  
- XGBoost  
- Matplotlib, Seaborn (visualizaciÃ³n)  

